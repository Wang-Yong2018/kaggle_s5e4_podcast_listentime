---
title: "manymodels_oldway"
output: html_document
---


## librar y & load_data

### library

```{r}
library(tidyverse)
library(tidymodels)
library(finetune)
library(future)
library(purrr)
library(furrr)
#library(textrecipes)
library(themis)
#library(embed)
#library(tailor)
library(furrr)

library(bonsai)
library(lightgbm)
library(xgboost)
library(ranger)
#library(betareg)
library(readr)
library(janitor)
library(lubridate)

library(memoise)
dk_cach <- memoise::cache_filesystem('./cache')
```
### download to local
```{r}
competition_name <- 'playground-series-s5e4'
data_path <- file.path('../input',competition_name)
target_name <- 'listening_time_minutes'
# system(paste0('kaggle competitions  download -c ', competition_name))
# unzip(paste0(competition_name,'.zip'),exdir=file.path('../input',competition_name))
# file.remove(paste0(competition_name,'.zip'))
```


### loading data

```{r}
train <-
  readr::read_csv(file.path(data_path, "train.csv"),
    show_col_types = FALSE
  ) |>
  janitor::clean_names()
test <-
  readr::read_csv(file.path(data_path, "test.csv"),
    show_col_types = FALSE
  ) |>
  janitor::clean_names()
submission <- readr::read_csv(file.path(data_path, "sample_submission.csv"), show_col_types = FALSE)
```

### get_outlier
```{r}



internal_get_outliers <- function(od_target){
  library(applicable)
  library(isotree)
  remove_cols <- c('id','listening_time_minutes')
  od_tr <- od_target |> select(-any_of(remove_cols))
  #od_te <- od_target |>  select(-any_of(remove_cols))
  if_mod <- apd_isolation(od_tr, ntrees = 100, nthreads = 4)
  od_score <- score(if_mod, od_tr) |>select('score_pctl')
  return(od_score)
}

get_outliers <- memoise::memoise(internal_get_outliers,cache=dk_cach)

```

### data nest 
```{r}
n <- 2
tr <- train |> bind_cols(get_outliers(train))|>
  nest(.by = podcast_name) |>
  head(n)
te <- test |>
  nest(.by = podcast_name) |>
  head(n)
```



```{r}
plt_density <- function(df,col_name='listening_time_minutes'){
  
  df|>
    ggplot(aes(x=.data[[col_name]])) + geom_density(alpha=0.5)+ theme_classic()
           
}
```

#### get_rcp
```{r}
get_rcp <- function(df) {
  rcp <-
    recipe(listening_time_minutes ~.,
           # episode_length_minutes
           #  +host_popularity_percentage
           #  #+guest_popularity_percentage
           #  +number_of_ads
           # # #+podcast_name 
           # # +episode_title
           # # +genre
           # # +publication_day
           # # +publication_time
           # +episode_sentiment
           # +score_pctl,
           data = df) |>
    update_role(id, new_role='ID')|>
    step_mutate(episode_length_minutes  = ifelse(episode_length_minutes  >= 0 & episode_length_minutes  <= 121,
                                                episode_length_minutes , 
                                                NA),
                number_of_ads  = ifelse(number_of_ads  >= 0 & number_of_ads  <= 5, number_of_ads ,  'NA'),
                has_guest=as.integer(is.na(guest_popularity_percentage)),
                has_length=as.integer(is.na(episode_length_minutes)))|>  
    ##step_impute_bag(all_numeric_predictors(),impute_with = imp_vars(number_of_ads,publication_day, publication_time, genre)) |>
    step_impute_median(all_numeric_predictors())|>
    step_impute_mode(all_nominal_predictors()) |>
    step_mutate( episode_id =as.integer(stringr::str_replace( episode_title, 'Episode ','')))|>  
    # Preprocessing steps (customize as needed)
    # step_naomit(all_predictors()) %>%       # Remove missing values
    step_rm(episode_title)|>
    #step_normalize(all_numeric_predictors()) %>% # Standardize numeric predictors
    step_novel(all_nominal_predictors()) |>
    step_unknown(all_nominal_predictors()) |>
    step_other(all_nominal_predictors()) |>
    step_dummy(all_nominal_predictors()) |> # One-hot encode categorical vars
    step_zv(all_predictors()) |>
    step_corr(all_predictors()) |>
    check_missing(all_predictors())
  return(rcp)
}
```

#### get_beta_mod
```{r}
get_beta_mod <- function(df){
   rmse_metrics <- metric_set(yardstick::rmse) # main goal is roc_auc, accuracy is just for reference
  set.seed(123)
  #df <- df|>bind_cols(df|>get_outliers())
  cv_folds <- vfold_cv(df, v = 3,strata = listening_time_minutes)
  
  lm_recipe  <- get_rcp(df)
  prep_df <- lm_recipe |> prep()|>juice()
  
  model <- betareg(
  listening_time_minutes ~ .,           # Formula (response ~ predictors)
  data = prep_df ,           # Dataframe
  link = "logit",        # Default link (others: "probit", "cloglog")
  link.phi = "log"       # Link for precision parameter (phi)
  )
  summary(model)           # Check coefficients & significance
  
}
```

#### get_mod
```{r}
get_mod <- function(df,return_type='resample') {
  
  rmse_metrics <- metric_set(yardstick::rmse) # main goal is roc_auc, accuracy is just for reference

  
  # 2. Create 3-Fold Cross-Validation Splits
  set.seed(123)
  #df <- df|>bind_cols(df|>get_outliers())
  cv_folds <- vfold_cv(df, v = 3,strata = listening_time_minutes)
  
  lm_recipe  <- get_rcp(df)
  
  # 3. Define Linear Regression Model
  lm_model <- linear_reg() %>% 
    set_engine("lm")
 
  lgbm_eng<-
   parsnip::boost_tree(
      trees = 200, # Number of trees
      learn_rate = 0.05,
      tree_depth =9,
      loss_reduction = 0.1,
      stop_iter = 50,
      sample_size = 0.8, # Added sample_size
      #tree_depth = tune(),
      #mtry = 0.5,
      min_n = 50
   ) |>
   set_mode("regression")|>
   set_engine("lightgbm",
              #metric='rmse', 
              num_leaves =210 ,
              #counts = FALSE,
              num_threads = 12,
              metric = "rmse",              # 优化目标
              # reg_alpha=0.01,
              # reg_lambda = 0.5,
              #verbose=1
              ) 

  
  # 4. Bundle into a Workflow
  lm_workflow <- workflow() %>% 
    add_recipe(lm_recipe) %>% 
    add_model(lm_model)
  
  if (return_type == "resample") {
    plan(multisession, workers = availableCores() - 1) 
    result <- lm_workflow |>
      fit_resamples(cv_folds,
        control = control_resamples(verbose = FALSE),
        metrics = rmse_metrics
      ) |>
      collect_metrics()
    plan(sequential)
  } else if (return_type == "fit") {
    result <- lm_workflow |>
      fit(df)
  }

  return(result)
}
```


#### get_predict
```{r}
get_predict<- function(wf,newdata,target_type='non'){
  
  .pred <- wf|>
    predict(newdata)
  
  if(target_type == 'log1p'){
    .pred <- .pred|> expm1()
  } else if( target_type == 'sqrt') {
    .pred <- .pred^2
  } else if(target_type =='beta') {
    .pred <- .pred |> rescale(to=c(0,120), from=c(0,1))
  }

  return(.pred)
}
```


```{r}

#plan(multisession, workers = availableCores() - 1) 
mm_fit <- tr |>
  mutate(cv_data = map(data, ~get_mod(.x),.progress = TRUE),
         model = future_map(data, ~get_mod(.x,return_type='fit'),.progress = TRUE))|>
  unnest(cv_data)

mm_fit|>
  mutate(glance=map(model, ~broom::glance(.x)))|>unnest(glance)
```
# diagnose
```{r}
library(ggfortify)
library(patchwork)
#mm_fit |> unnest(data ) |> select(podcast_name, listening_time_minutes) |>nest(.by=podcast_name,.key = 'true')
mm_fit <- 
  mm_fit|> 
  rowwise()|> mutate(true = list(pluck(data, 'listening_time_minutes')))|>
  mutate(.pred=list(get_predict(model, data, target_type = 'none'))) |>
  rowwise()|>mutate(rmse_score = yardstick::rmse_vec(truth=true, estimate=.pred$.pred
                                                     ))

tmp_true <- mm_fit |> pluck('true',1)
tmp_pred <- mm_fit |> pluck('.pred',1,1)
tmp_target <- tibble("true"=tmp_true, "pred"=tmp_pred)
tmp_target |> 
  pivot_longer(cols=everything())|>
  ggplot(aes(x=value,color=name))+geom_density()

Dtmp_mod <- mm_fit$model[[1]] |>extract_fit_engine()
#tmp_mod |> tidy()
#tmp_mod|>glance()
#mm_fit|> rowwise()|>mutate(true = list(select(data, listening_time_minutes))) |> mutate(.pred=list(get_predict(model, data))) 
#tmp_mod |>autoplot()
```

## betaregression check
### compare the response variable distribution
```{r}

library(betareg)
library(fitdistrplus)

get_fitdist_info<-function(df, col_name='listening_time_minutes'){
  
 original_y <- df[[col_name]]
 y <- original_y  / 120 +0.001/120  # 缩放到 [0,1]
 stringr::str_glue('the lisenting time value range is {min(original_y)}--{max(original_y)} (minutes)')

 # (1) 正态分布拟合
 fit_normal <- fitdist(y, "norm")

  # (2) Beta 分布（需要缩放到 0~1）
  fit_beta <- fitdist(y, "beta", method = "mme")  # 矩估计法
  
  # (3) Gamma 分布
  fit_gamma <- fitdist(y, "gamma")
  
  # (4) 对数正态分布（如果 y > 0）
   fit_lnorm <- fitdist(y, "lnorm")
  
  # 比较AIC 
  gof_stats <- gofstat(list(fit_normal, fit_beta, fit_gamma, fit_lnorm),
                     fitnames = c("Normal", "Beta", "Gamma", "Lognormal"))
   print(gof_stats)
  # par(mfrow = c(2, 2))
  # plot(fit_normal, main = "Normal")
  # plot(fit_beta, main = "Beta")
  # plot(fit_gamma, main = "Gamma")
  # plot(fit_lnorm, main = "Lognormal")
   
}


get_fitdist_info()
```


# predict
```{r}
mm_fit |> ggplot(aes(x = sigma, y = adj.r.squared)) +
  geom_jitter()

te <- test |> head()
nest(.by = podcast_name) |>
  select(podcast_name, te_data = data)
combined <- left_join(te, mm_fit, by = "podcast_name")

combined |>
  head() |>
  mutate(.pred = map2(models, te_data, predict)) -> tmp_pred
tmp_pred
```


```{r}
library(embed) 
tmp_df <- tr|>dplyr::slice(1)|>unnest(data)|>mutate(episode_id =as.integer(stringr::str_replace( episode_title, 'Episode ','')))

lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")


lm_rcp <- 
  recipe(listening_time_minutes ~ episode_length_minutes+guest_popularity_percentage+episode_id, data = tmp_df)|>
#  step_mutate( episode_id =as.integer(stringr::str_replace( episode_title, 'Episode ','')))|>  
  step_mutate(guest_popularity_percentage=replace_na(guest_popularity_percentage,0 ),
              has_guest=ifelse(is.na(guest_popularity_percentage),0,1))|>
  step_impute_linear(episode_length_minutes,impute_with = imp_vars(episode_id))|>
  step_rm(all_nominal_predictors())|>
  check_missing(all_predictors())

lm_wf <- workflow() %>%
  add_model(lm_spec) %>%
  add_recipe(lm_rcp)


lm_fit <- lm_wf %>%
  fit(tmp_df)
lm_fit|>glance()
lm_fit|>tidy()
```

